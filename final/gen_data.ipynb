{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {\n",
    "    1: 'normal',\n",
    "    2: 'aom',\n",
    "    3: 'ome',\n",
    "    4: 'csom',\n",
    "    5: 'myringosclerosis',\n",
    "    6: 'earwax',\n",
    "    7: 'tube'\n",
    "}\n",
    "\n",
    "classes = [1, 4, 5, 6]\n",
    "\n",
    "CLASS_NAMES = [class_dict[i] for i in classes]\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "randomiser = np.random.RandomState(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_folder = \"./original\"\n",
    "exp_folder = \"./experiment\"\n",
    "\n",
    "orig_dataset1 = os.path.join(orig_folder, \"1\")\n",
    "orig_dataset2 = os.path.join(orig_folder, \"2/Training-validation\")\n",
    "orig_dataset3 = os.path.join(orig_folder, \"3\")\n",
    "\n",
    "exp_dataset1 = os.path.join(exp_folder, \"1\")\n",
    "exp_dataset2 = os.path.join(exp_folder, \"2\")\n",
    "exp_dataset3 = os.path.join(exp_folder, \"3\")\n",
    "exp_dataset4 = os.path.join(exp_folder, \"4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, class_names):\n",
    "    full_data = []\n",
    "    \n",
    "    class_dict = {}\n",
    "    for i, name in enumerate(class_names):\n",
    "        class_dict[name] = i\n",
    "    \n",
    "    for d in class_names:\n",
    "        dirpath = os.path.join(path, d)\n",
    "        if not os.path.exists(dirpath): continue\n",
    "        image_files = [f for f in os.listdir(dirpath) if f.endswith(('.jpg', '.png', 'jpeg'))]\n",
    "        label = d\n",
    "        for img in image_files:\n",
    "            image = Image.open(os.path.join(dirpath, img))\n",
    "            \n",
    "            image = tf.cast(image, tf.float32)/255.0\n",
    "            \n",
    "            data = np.array([image, class_dict[label]], dtype=object)\n",
    "            full_data.append(data)\n",
    "    \n",
    "    randomiser.shuffle(np.array(full_data))\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(full_data, train, validation):\n",
    "    X_full = np.array([x[0] for x in full_data], dtype=object)\n",
    "    y_full = np.array([y[1] for y in full_data])\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_full, y_full, train_size=train, stratify=y_full, random_state=RANDOM_STATE)\n",
    "    X_val = []\n",
    "    y_val = []\n",
    "    \n",
    "\n",
    "    validation = validation / (1.0 - train)\n",
    "    \n",
    "    if validation >= 1:\n",
    "        X_val = X_test\n",
    "        y_val = y_test\n",
    "        X_test = []\n",
    "        y_test = []\n",
    "        \n",
    "    elif validation > 0:\n",
    "        X_val, X_test, y_val, y_test = train_test_split(\n",
    "                X_test, y_test, train_size=validation, stratify=y_test, random_state=RANDOM_STATE)\n",
    "    \n",
    "    return [(X_train, y_train), (X_val, y_val), (X_test, y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(path, class_names, da=0, train=0.7, val=0.1, da_dict={}):     \n",
    "    class_names = [c for c in class_names if c in os.listdir(path)]\n",
    "    full_data = load_dataset(path, class_names)\n",
    "    sets = split_data(full_data, train, val)\n",
    "    train_orig = sets[0]\n",
    "    # sets[0] = data_augmentation(da, train_orig[0], train_orig[1], da_dict)\n",
    "    print(class_names)\n",
    "    print(np.bincount(train_orig[1]))\n",
    "    print(np.bincount(sets[0][1]))\n",
    "    print(np.bincount(sets[0][1]) // np.bincount(train_orig[1]))\n",
    "    \n",
    "    print()\n",
    "    for s in sets:\n",
    "        print(np.bincount(s[1]))\n",
    "        \n",
    "    return (sets, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(path_to_save, X, y, class_names):\n",
    "    def uniquify(path):\n",
    "        filename, extension = os.path.splitext(path)\n",
    "        counter = 1\n",
    "\n",
    "        while os.path.exists(path):\n",
    "            path = filename + \" (\" + str(counter) + \")\" + extension\n",
    "            counter += 1\n",
    "\n",
    "        return path\n",
    "    \n",
    "    os.makedirs(os.path.dirname(path_to_save), exist_ok=True)\n",
    "    for i in range(len(X)):\n",
    "        img = np.array(X[i])\n",
    "        label = y[i] \n",
    "        path = (os.path.join(path_to_save, class_names[label], class_names[label]+'.jpeg'))\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "        path = uniquify(path)\n",
    "        im = Image.fromarray((img * 255).astype(np.uint8))\n",
    "        im.save(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(path, sets, class_names):\n",
    "    paths = ['training', 'validation', 'testing']\n",
    "    for i, p in enumerate(paths):\n",
    "        data = sets[0]\n",
    "        X = sets[i][0]\n",
    "        y = sets[i][1]\n",
    "        p = os.path.join(path, p)\n",
    "        save_images(p, X, y, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['normal', 'csom', 'myringosclerosis', 'earwax']\n",
      "[155 155 154 155]\n",
      "[155 155 154 155]\n",
      "[1 1 1 1]\n",
      "\n",
      "[155 155 154 155]\n",
      "[22 21 22 21]\n",
      "[3 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "# Dataset 2\n",
    "res = get_dataset(orig_dataset2, CLASS_NAMES, 0, 0.86, 0.12)\n",
    "save_data(exp_dataset2, res[0], res[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['normal', 'csom', 'myringosclerosis', 'earwax']\n",
      "[374  44  20  98]\n",
      "[374  44  20  98]\n",
      "[1 1 1 1]\n",
      "\n",
      "[374  44  20  98]\n",
      "[53  6  3 14]\n",
      "[108  13   5  28]\n"
     ]
    }
   ],
   "source": [
    "# Dataset 3\n",
    "res = get_dataset(orig_dataset3, CLASS_NAMES)\n",
    "save_data(exp_dataset3, res[0], res[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory_path = \"./experiment/2/testing/normal/\"\n",
    "count = 4\n",
    "\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.startswith(\"tochange\"):\n",
    "        old_path = os.path.join(directory_path, filename)\n",
    "        new_name = f\"normal ({count}).jpeg\"\n",
    "        new_path = os.path.join(directory_path, new_name)\n",
    "        os.rename(old_path, new_path)\n",
    "        count += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
